<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
 
 <title>Optimal.io</title>
 <link href="/" rel="self"/>
 <link href=""/>
 <updated>2014-08-05T10:37:25-05:00</updated>
 <id></id>
 <author>
   <name>Name Lastname</name>
   <email>blah@email.test</email>
 </author>

 
 <entry>
   <title>How we are building Alexa for the mobile industry.</title>
   <link href="/Building-Alexa-For-Mobile-Statistics"/>
   <updated>2014-06-22T00:00:00-05:00</updated>
   <id>/Building-Alexa-For-Mobile-Statistics</id>
   <content type="html">&lt;p&gt;&lt;em&gt;Where is the Univeral Mobile Statistics Site ?&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;It’s a mobile world - everybody knows that. It’s been like this for almost a decade now. The funniest thing is that we still don’t have an &lt;a href=&quot;http://www.Alexa.com&quot;&gt;Alexa&lt;/a&gt; for the mobile industry. There is no publicly available source currently which I can take a look at to see where my / my company’s mobile application ranks amongst other apps of the sametype. There are challenges to get statistics from mobile applications - distribute processing, offline/online support, hybrid applications all lead to &lt;/p&gt;

&lt;p&gt;In my opinion there are three ways to do this.  &lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Google could ask their Google Analytics mobile users to publish their mobile statistics publicly.&lt;/strong&gt; &lt;/p&gt;

    &lt;p&gt;I know that this is a completely different model which will conflict with their existing service model where the end customers will not agree to because its their ‘private’ metrics. &lt;/p&gt;

    &lt;p&gt;Even if Google goes down with this model, there is a challenge of proving that the metrics is correct. What I mean by that is that the Analytics code ( UA-*** ) could have been used in one of the company’s existing mobile application which was already popular and therefore prevents an easy verifiable method to prove the identity of the mobile application.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Users call an api to publish their user statistics.&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;Again this proves to be a non-verifiable way of ensuring the statistics is accurate.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;A 3rd Party runs device level statistics and collects it centrally.&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;A mobile phone is a personal device.  Running a process there to collect information requires permissions from users and has an intrinsic resistance built up. But if you think through this problem, and if use inferential statistics, you could identify a sample which represents your population you want to get data from. You could incentivize them to get the data you need (ie. sending only app related data back to your servers).   &lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;which-option-did-we-choose&quot;&gt;Which option did we choose?&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;We, at &lt;a href=&quot;http://www.SurveyAnalytics.com&quot;&gt;Survey Analytics&lt;/a&gt; have chosen going down the path of #3 above. As a company it was an easy path for us because we already had a Panel management software. Just to help you understand -  a Panel management software typically supports survey panels which allows you to create a list of respondents that you can invite to participate in surveys over and over again. These respondents are referred to as panelists, where each panelist subscribes to a survey panel and provides demographic information about himself/herself. The incentives for the respondents vary depending on how motivated they are to provide feedback.&lt;/p&gt;

&lt;p&gt;What we did was tweak this infrastructure to ask permission to collect ‘passive’ data.  So essentially from a panelist’s standpoint they first download a mobile application (called SurveySwipe) and as soon as they login for the first time they get prompted with the Terms and Conditions (T&amp;amp;C) to collect non personal data from their mobile applications. The most important thing in terms of design is that the collection of the data is based on ‘triggers’ so that we don’t collect data always but based it on days of the week and time of the day or an external trigger like filling out a survey.&lt;/p&gt;

&lt;h2 id=&quot;results-of-running-on-a-panel-of-users-for-3-months&quot;&gt;Results of running on a Panel of users for 3 months&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;Here are some of the key statistics of the panel we used to collect mobile app usage metrics :&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;- 990 people participated 
- Incentives like Amazon Gift cards were given for participation 
- Females : 57%
- 56% had an undergraduate degree
- 14% had an income over $150K
- Data collected over 3 months
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We collected ‘passively’ the data around the top mobile apps running on this panel. Here is the chart produced for the most frequently running apps.&lt;/p&gt;

&lt;p&gt;After we got the data on the servers, we used R to ensure we have complete samples and this is what we got :&lt;/p&gt;

&lt;h3 id=&quot;top-moble-apps-running-in-our-panel&quot;&gt;Top Moble Apps running in our panel&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/TopRunningMobileApps-Alexa.png&quot; alt=&quot;Top Mobile Apps Running in the Panel&quot; title=&quot;Like Alexa's statistics : Top Mobile Apps Running&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;frequency-counts-of-the-mobile-applications-screenshot-from-r-console&quot;&gt;Frequency counts of the mobile applications (screenshot from R console)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/top-running-mobile-apps-r-results.png&quot; alt=&quot;Frequency count of Moble Apps running &quot; title=&quot;Like Alexa's statistics : Count of Mobile Apps Running&quot; /&gt;&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>What are the different type of questions a Data Scientist would ask ?</title>
   <link href="/Different-type-of-questions-in-data-science"/>
   <updated>2014-05-18T00:00:00-05:00</updated>
   <id>/Different-type-of-questions-in-data-science</id>
   <content type="html">&lt;p&gt;These are the different classifications of questions a Data Scientist can ask :&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Exploratory&lt;/strong&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Descriptive&lt;/strong&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Inferential&lt;/strong&gt;
Often, you do not have access to the whole data (better called population) you are interested in investigating, but only a limited number of data instead. For example, you might be interested in the exam marks of all students in Canada. It is not feasible to measure all exam marks of all students in the whole of Canada, so you have to measure a smaller sample of students (e.g., 100 students), which are used to represent the larger population of all Canada students. Properties of samples, such as the mean or standard deviation, are not called parameters, but statistics. Inferential statistics are techniques that allow us to use these samples to make generalizations about the populations from which the samples were drawn.&lt;/p&gt;

    &lt;p&gt;Usually almost every statistics driven company uses this to publish results. For example, Nielson ratings gather information from a small sample of homes and are used to infer the television-viewing patterns of an entire country.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Predictive&lt;/strong&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Causal&lt;/strong&gt;
Causal question are usually asked to find out what happens to one variable when you change another.&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;Implementation usually requires randomized studies&lt;/li&gt;
      &lt;li&gt;There are approaches to inferring causation in non-randomized studies&lt;/li&gt;
      &lt;li&gt;Causal models are said to be the “gold standard” for data analysis&lt;/li&gt;
      &lt;li&gt;Type of data set applied to: Randomized Trial Data Set – data from a randomized study&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;Causal analysis aims to explain the causal relations between variables. If you want to indicate explicit causality, your study must include an experiment. You compare the control and treatment groups, for example, with variance analysis.  i&lt;/p&gt;

    &lt;p&gt;You may also use regression analysis, which measures causality in a weaker way. Regression analysis enables you to explore the influence of several variables on a single variable at the same time. Regression analysis may also focus on exploring the intensity of the influence of a single variable.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Mechanistic&lt;/strong&gt;
Mechanistic type of modelling requires the most amount of effort. It requires you to understand the exact changes in variables that lead to changes in other variables for individual objects.&lt;/p&gt;

    &lt;pre&gt;&lt;code&gt; &quot;All other things being equal, mechanistic models are more powerful since they tell you 
 about the underlying processes driving patterns. They are more likely to work 
 correctly when extrapolating beyond the observed conditions.&quot;
 -Bolker (2008) Ecological models and Data in R, p7.
&lt;/code&gt;&lt;/pre&gt;

    &lt;ul&gt;
      &lt;li&gt;Incredibly hard to infer, except in simple situations&lt;/li&gt;
      &lt;li&gt;Usually modeled by a deterministic set of equations (physical/engineering science)&lt;/li&gt;
      &lt;li&gt;Generally the random component of the data is measurement error&lt;/li&gt;
      &lt;li&gt;If the equations are known but the parameters are not, they may be inferred with data analysis&lt;/li&gt;
      &lt;li&gt;Type of data set applied to: Randomized Trial Data Set – data about all components of the system&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

</content>
 </entry>
 
 <entry>
   <title>How to add a SVG image in D3</title>
   <link href="/how-to-add-a-svg-image-in-d3"/>
   <updated>2014-01-02T00:00:00-06:00</updated>
   <id>/how-to-add-a-svg-image-in-d3</id>
   <content type="html">&lt;p&gt;First of all - Happy 2014 to all of you!.&lt;/p&gt;

&lt;p&gt;In D3, you have the option of importing XML. SVG is and XML based vector image format.&lt;/p&gt;

&lt;table class=&quot;highlighttable&quot;&gt;&lt;tr&gt;&lt;td class=&quot;linenos&quot;&gt;&lt;div class=&quot;linenodiv&quot;&gt;&lt;pre&gt;&lt;code class=&quot;javascript&quot;&gt; 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;span class=&quot;nx&quot;&gt;d3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;xml&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;/assets/infographics/&amp;quot;&lt;/span&gt; 
       &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;svgSource&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
&lt;span class=&quot;s2&quot;&gt;&amp;quot;image/svg+xml&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
&lt;span class=&quot;kd&quot;&gt;function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;xml&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;			
 &lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;importedNode&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;document&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;importNode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;xml&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;documentElement&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
	
	&lt;span class=&quot;nx&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;#svg-image&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;find&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;g#&amp;#39;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;xml&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;documentElement&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;clone&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;());&lt;/span&gt;
			&lt;span class=&quot;nx&quot;&gt;container&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;attr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;x&amp;quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;200px&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
			&lt;span class=&quot;nx&quot;&gt;container&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;attr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;y&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;200px&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
 &lt;span class=&quot;p&quot;&gt;});&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;

&lt;p&gt;If you are interested in generating dynamic Infographics automatically - try Secondprism’s 
&lt;a href=&quot;http://app.secondprism.com/assets/product/infographic_for_dashboard.html&quot;&gt;Infographic generator here&lt;/a&gt;.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>3 simple steps to create cross-tabs in SPSS ?</title>
   <link href="/how-to-create-crosstabs-in-spss-in-3-simple-steps"/>
   <updated>2013-10-09T00:00:00-05:00</updated>
   <id>/how-to-create-crosstabs-in-spss-in-3-simple-steps</id>
   <content type="html">&lt;h3 id=&quot;step-1---get-the-spss-file-and-understand-which-variables-you-will-be-using-for-your-crosstabs&quot;&gt;Step 1 - Get the SPSS file and understand which variables you will be using for your crosstabs.&lt;/h3&gt;

&lt;p&gt;I had the following source file and wanted to find out differences between shopping behaviour of Males and Females for a specific event.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/spss-input-file-for-analysis.png&quot; alt=&quot;SPSS Source file for cross tabs&quot; title=&quot;SPSS file&quot; /&gt;&lt;/p&gt;

&lt;p&gt;My independent variables  are therefore - Gender ( Male, Female)  and my dependent varable is the question  - ‘Do you shop on Black Friday?’&lt;/p&gt;

&lt;h3 id=&quot;step-2---add-the-variables-on-spss-under-analyze--descriptives--crosstabs&quot;&gt;Step 2 - Add the variables on SPSS under Analyze &amp;gt; Descriptives &amp;gt; Crosstabs&lt;/h3&gt;

&lt;p&gt;Check the screenshot below&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/spss-crosstab-menu-option.png&quot; alt=&quot;SPSS Menu for Crosstabs&quot; title=&quot;SPSS Menu for Crosstab&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Choose the variables you want to see in the crosstab&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/spss-cross-tab-variables.png&quot; alt=&quot;SPSS Variables for Crosstabs&quot; title=&quot;Select variables for SPSS Crosstab&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;step-3---create-crosstab-with-percentage-values&quot;&gt;Step 3 - Create Crosstab with percentage values&lt;/h3&gt;

&lt;p&gt;Then choose the Statistics option &amp;gt; Chi-square&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/spss-chi-square.png&quot; alt=&quot;SPSS Chi-square&quot; title=&quot;SPSS Chi-square&quot; /&gt;&lt;/p&gt;

&lt;p&gt;And under option Cells, ensure you have clicked on Percentage &amp;gt; Columns&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/spss-crosstab-column-percentage.png&quot; alt=&quot;SPSS Column percentage&quot; title=&quot;SPSS column percentage&quot; /&gt;&lt;/p&gt;

&lt;p&gt;And once you have this setup you can generate the report which looks like this for my example:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/crosstab-report-generated-from-spss.png&quot; alt=&quot;SPSS Crosstab report&quot; title=&quot;SPSS Crosstab report&quot; /&gt; &lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>What is a Dichotomous Variable?</title>
   <link href="/What-is-a-dichotomous-variable"/>
   <updated>2013-10-09T00:00:00-05:00</updated>
   <id>/What-is-a-dichotomous-variable</id>
   <content type="html">&lt;p&gt;A very complicated name for a very simple thing. It is also called Dichotomous outcome variable or just Dichotomous outcome. It  means “having only two possible values”, e.g. “yes/no”, “male/female”, “head/tail”, “age &amp;gt; 35 / age &amp;lt;= 35” etc. From a data capture standpoint, these are usually captured on surveys as radio buttons.&lt;/p&gt;

&lt;p&gt;The outcome of an experiment with coin tossing is dichotomous (“head” or “tail”); the variable “biological sex” in a social study is dichotomous (“male” or “female”).
Dichotomous variables are the simplest and intuitively clear type of random variable s. For this reason mental (and real) coin-tossing experiments are often used in introductory courses in statistics and probability. Nevertheless, statistical methods developed for analysis of dichotomous variables are often more complex, both conceptually and mathematically, than parallel methods for continuous variables.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Introduction to Bayesian analysis</title>
   <link href="/introduction-to-bayesian-analysis"/>
   <updated>2013-09-21T00:00:00-05:00</updated>
   <id>/introduction-to-bayesian-analysis</id>
   <content type="html">&lt;p&gt;The key ingredients to a Bayesian analysis are the likelihood function, which reﬂects information about the parameters contained in the data, and the prior distribution, which quantiﬁes what is known about the parameters before observing data.
The prior distribution and likelihood can be easily combined to form the posterior distribution, which represents total knowledge about the parameters after the data have been observed.&lt;/p&gt;

&lt;h3 id=&quot;fundamentals-of-a-bayesian-analysis&quot;&gt;Fundamentals of a Bayesian Analysis&lt;/h3&gt;

&lt;p&gt;A typical Bayesian analysis can be outlined in the following steps :&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Formulate a probability model for the data.&lt;/li&gt;
  &lt;li&gt;Decide on a prior distribution, which quantiﬁes the uncertainty in the values of the unknown model parameters before the data are observed.&lt;/li&gt;
  &lt;li&gt;Observe the data, and construct the likelihood function ) based on the data and the probability model formulated in step 1. The likelihood is then combined with the prior distribution from step 2 to determine the posterior distribution, which quantiﬁes the uncertainty in the values of the unknown model parameters after the data are observed.&lt;/li&gt;
  &lt;li&gt;Summarize important features of the posterior distribution, or calculate quantities of interest based on the posterior distribution. These quantities constitute statistical outputs, such as point estimates and intervals.&lt;/li&gt;
&lt;/ol&gt;
</content>
 </entry>
 
 <entry>
   <title>Introduction to Decision Trees</title>
   <link href="/introduction-to-decision-trees"/>
   <updated>2013-09-18T00:00:00-05:00</updated>
   <id>/introduction-to-decision-trees</id>
   <content type="html">&lt;p&gt;A decision tree is a classic and natural model of learning. It can be applied to many machine learning problems. The best way to introduce this would be with an example using binary classiﬁcation.&lt;/p&gt;

&lt;p&gt;Suppose that your goal is to predict whether some unknown passenger in  will enjoy some unknown future flight he/she is going to take. You have to simply predict with an answer of  “yes”or “no.”
In order to make a guess, your’re allowed to ask binary questions about the passenger under consideration.&lt;/p&gt;

&lt;p&gt;For example:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;ruby&quot;&gt;&lt;span class=&quot;ss&quot;&gt;Machine&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Are&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;you&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;going&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;on&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vacation?&lt;/span&gt;
&lt;span class=&quot;ss&quot;&gt;You&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Yes&lt;/span&gt;
&lt;span class=&quot;ss&quot;&gt;Machine&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Is&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;the&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;flight&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;early&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;morning?&lt;/span&gt;
&lt;span class=&quot;ss&quot;&gt;You&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Yes&lt;/span&gt;
&lt;span class=&quot;ss&quot;&gt;Machine&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Is&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;the&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;flight&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;more&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;than&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hours?&lt;/span&gt;
&lt;span class=&quot;ss&quot;&gt;You&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;Yes&lt;/span&gt;
&lt;span class=&quot;ss&quot;&gt;Machine&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;I&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;this&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;passenger&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;will&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;enjoy&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;the&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;flight&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The goal in learning is to ﬁgure out what questions to ask, in whatorder to ask them, and what answer to predict once you have askedenough questions.
The decision tree is so-called because we can write our set of questions and guesses in a tree format. Usually the answers would decide how to navigate the tree.
Diagramatically, the questions are usually written in the internal nodes (rectangles) and the guesses are written in the leaves (ovals). Each non-terminal node has two children: the left child speciﬁes what to do if the answer to the question is “no” and the right child speciﬁes what to do ifit is “yes.”&lt;/p&gt;

&lt;p&gt;More learning at  &lt;a href=&quot;http://www.optimal.io&quot;&gt;Optimal.io&lt;/a&gt; &lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>4 Typical inductive learning problems</title>
   <link href="/4-typical-inductive-learning-problems"/>
   <updated>2013-09-16T00:00:00-05:00</updated>
   <id>/4-typical-inductive-learning-problems</id>
   <content type="html">&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Regression&lt;/strong&gt; : trying to predict a real value. For instance, predict the value of a stock tomorrow given its past performance. Or predictyour score on the data science ﬁnal exam based on your homework scores.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Binary Classiﬁcation&lt;/strong&gt; : trying to predict a simple yes/no response.For instance, predict whether you will enjoy this material or not.Or predict whether a user review of the newest Google product is positive or negative about the product.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Multiclass Classiﬁcation&lt;/strong&gt; : trying to put an example into one of a number of classes. For instance, predict whether a news story is about entertainment, sports, politics, religion, etc. Or predict whether a CS course is Systems, Theory, AI or Other.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Ranking&lt;/strong&gt; : trying to put a set of objects in order of relevance. For instance, predicting what order to put web pages in, in response to a user query. Or predict Alice’s ranked preferences over courses she hasn’t taken.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;More learning @ &lt;a href=&quot;http://www.optimal.io&quot;&gt;Optimal.io&lt;/a&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Sharding in MongoDB</title>
   <link href="/sharding-in-mongodb"/>
   <updated>2013-09-13T00:00:00-05:00</updated>
   <id>/sharding-in-mongodb</id>
   <content type="html">&lt;p&gt;Sharding, can also be called horizontal scaling. The scaling approach divides the data set and distributes the data over multiple servers. Each of this server can be called a shard. Each shard is an independent database, and collectively, the shards make up a single logical database. &lt;/p&gt;

&lt;h3 id=&quot;what-other-components-are-required-for-mongodb-sharding&quot;&gt;What other components are required for MongoDB sharding?&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;/assets/img/how-to-do-mongodb-sharding.png&quot; alt=&quot;Horizontal scaling using MongoDB sharding&quot; title=&quot;MongoDB sharding&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Like mentioned above, the Shards stores the data. For ensuring that shards are highly available, you need to have replica sets . We will go into more details later around replica sets, but for now the easiest way to explain this is - you could have a primary shard which you can write to and a second shard which is paired with the primary shard hosting the same data which you can read from.
When you do sharding, you would need to know which shard to get the data from.  This is done by the Query Router. The Query Router direct requests to the appropriate shard or shards. It processes and targets operations to shards and then returns results to the clients. &lt;/p&gt;

&lt;h3 id=&quot;how-does-the-query-router-know-which-shard-to-get-the-data-from&quot;&gt;How does the query router know which shard to get the data from ?&lt;/h3&gt;
&lt;p&gt;This information is stored in Config servers. They store the cluster’s metadata. This data contains a mapping of the cluster’s data set to the shards. The query router uses this data to route requests to the right shards.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>NoSQL vs SQL Comparison Summary</title>
   <link href="/nosql-vs-sql-comparison-summary"/>
   <updated>2013-09-09T00:00:00-05:00</updated>
   <id>/nosql-vs-sql-comparison-summary</id>
   <content type="html">&lt;h2 id=&quot;types&quot;&gt;Types&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;SQL&lt;/strong&gt; : One type (SQL database) with minor variations&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;NOSQL&lt;/strong&gt; : Many different types including key-value stores, document databases, wide-column stores, and graph databases
 
Schemas
——-
&lt;strong&gt;SQL&lt;/strong&gt;: Structure and data types are fixed in advance. To store information about a new data item, the entire database must be altered, during which time the database must be taken offline.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;NOSQL&lt;/strong&gt;: Typically dynamic. Records can add new information on the fly, and unlike SQL table rows, dissimilar data can be stored together as necessary. For some databases (e.g., wide-column stores), it is somewhat more challenging to add new fields dynamically.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>How to find the schema of a collection in MongoDB</title>
   <link href="/how-to-find-the-schema-of-a-collection-in-mongodb"/>
   <updated>2013-09-09T00:00:00-05:00</updated>
   <id>/how-to-find-the-schema-of-a-collection-in-mongodb</id>
   <content type="html">&lt;p&gt;The last two commands are equivalent to the SQL command below&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;sql&quot;&gt;&lt;span class=&quot;k&quot;&gt;Describe&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;Table&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Open a mongo shell and run the following commands :&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;bash&quot;&gt;MongoDB shell version: 2.4.5
&amp;gt; show dbs
&lt;span class=&quot;nb&quot;&gt;local &lt;/span&gt;0.078125GB
todo 0.453125GB
&amp;gt; use todo
switched to db todo
&amp;gt; show collections
system.indexes
tasks
&amp;gt; var &lt;span class=&quot;nv&quot;&gt;schematodo&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; db.tasks.findOne&lt;span class=&quot;o&quot;&gt;()&lt;/span&gt;;
&amp;gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;var key in schematodo&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt; print &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;key&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; ; &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
_id
label
content
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

</content>
 </entry>
 
 <entry>
   <title>4 use cases of using MongoDB and Hadoop together</title>
   <link href="/4-use-cases-of-using-mongodb-and-hadoop-together"/>
   <updated>2013-09-08T00:00:00-05:00</updated>
   <id>/4-use-cases-of-using-mongodb-and-hadoop-together</id>
   <content type="html">&lt;p&gt;&lt;img src=&quot;/assets/img/hadoop-batch-aggregation.png&quot; alt=&quot;Hadoop Data Warehouse&quot; title=&quot;Hadoop Batch Aggregation&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/hadoop-data-warehouse.png&quot; alt=&quot;Hadoop Data Warehouse&quot; title=&quot;Hadoop Data Warehouse&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/hadoop-etl-from-mongodb.png&quot; alt=&quot;Hadoop ETL from MongoDB&quot; title=&quot;Hadoop ETL from MongoDB&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/hadoop-etl-to-mongodb.png&quot; alt=&quot;Hadoop ETL to MongoDB&quot; title=&quot;Hadoop ETL to MongoDB&quot; /&gt;&lt;/p&gt;

&lt;p&gt;You can read about the use cases here at MongoDB.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Big Data Applications - 2013</title>
   <link href="/big-data-applications-2013"/>
   <updated>2013-09-07T00:00:00-05:00</updated>
   <id>/big-data-applications-2013</id>
   <content type="html">&lt;h2 id=&quot;here-are-the-companies-in-the-big-data-application-stack&quot;&gt;Here are the companies in the Big Data application stack&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/big-data-applications.png&quot; alt=&quot;Big Data Applications&quot; title=&quot;These are applications who are playing in the Big data space&quot; /&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Hadoop Data Types</title>
   <link href="/hadoop-data-types"/>
   <updated>2013-09-06T00:00:00-05:00</updated>
   <id>/hadoop-data-types</id>
   <content type="html">&lt;p&gt;Here is a high level overview of Writable and InputFormat Data types which are used in Hadoop&lt;/p&gt;

&lt;p&gt;Here is a Detailed class diagram for these two data types. Thanks to Xu Fei&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/hadoop-data-type-inputformat-interface.png&quot; alt=&quot;Hadoop Input Format Interface&quot; title=&quot;Hadoop Input Format Interface&quot; /&gt;
&lt;img src=&quot;/assets/img/hadoop-data-type-writable-interface.png&quot; alt=&quot;Hadoop Writable Interface&quot; title=&quot;Hadoop Writable Interface&quot; /&gt;&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>3 Differences between a MapReduce Combiner and Reducer ?</title>
   <link href="/3-differences-between-a-mapreduce-combiner-and-reducer"/>
   <updated>2013-09-05T00:00:00-05:00</updated>
   <id>/3-differences-between-a-mapreduce-combiner-and-reducer</id>
   <content type="html">&lt;p&gt;Think of a Combiner as a function of your map output. This you can primarily use for decreasing the amount of data needed to be processed by Reducers. In some cases, because of the nature of the algorithm you implement, this function can be the same as the Reducer. But in some other cases this function can of course be different.&lt;/p&gt;

&lt;p&gt;A combiner will still be implementing the Reducer interface. Combiners can only be used in specific cases which are going to be job dependent. &lt;/p&gt;

&lt;h2 id=&quot;difference--1&quot;&gt;Difference # 1&lt;/h2&gt;
&lt;p&gt;One constraint that a Combiner will have, unlike a Reducer, is that the input/output key and value types must match the output types of your Mapper.&lt;/p&gt;

&lt;h2 id=&quot;difference-2&quot;&gt;Difference  #2&lt;/h2&gt;
&lt;p&gt;Combiners can only be used on the functions that are commutative(a.b = b.a) and associative {a.(b.c) = (a.b).c} . This also means that combiners may operate only on a subset of your keys and values or may not execute at all, still you want the output of the program to remain same.&lt;/p&gt;

&lt;h2 id=&quot;difference-3&quot;&gt;Difference  #3&lt;/h2&gt;
&lt;p&gt;Reducers can get data from multiple Mappers as part of the partitioning process. Combiners can only get its input from one Mapper.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>4 Types of Data Scientist related Roles</title>
   <link href="/4-types-of-data-scientist-related-roles"/>
   <updated>2013-09-04T00:00:00-05:00</updated>
   <id>/4-types-of-data-scientist-related-roles</id>
   <content type="html">&lt;p&gt;&lt;img src=&quot;/assets/img/Types-of-data-scientists.png&quot; alt=&quot;4 Types of Data Scientists&quot; title=&quot;Types of Data Scientists&quot; /&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>What is Binning?</title>
   <link href="/what-is-binning"/>
   <updated>2013-09-03T00:00:00-05:00</updated>
   <id>/what-is-binning</id>
   <content type="html">&lt;p&gt;Binning is a way to group a number of more or less continuous values into a smaller number of “bins”. For example, if you have data about a group of people, you might want to arrange their ages into a smaller number of age intervals. 
In the example below, we have data about temperature in a region ordered based on the date of the month. It is hard to visualize what the range of temperature was for that region was.
ccc&lt;/p&gt;

&lt;p&gt;Binning helps in visualizing these values. The first step is to find the occurences of the temperature. The table below shows occurences of a temperature range.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/binning-example-for-statistics-bargraphs.png&quot; alt=&quot;Binning example of statistics in bargraphs&quot; title=&quot;Binning example&quot; /&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>What is an ElasticSearch Facet ?</title>
   <link href="/what-is-an-elasticsearch-facet"/>
   <updated>2013-09-03T00:00:00-05:00</updated>
   <id>/what-is-an-elasticsearch-facet</id>
   <content type="html">&lt;p&gt;LinkedIn uses facets to refine their search query.
In ElasticSearch, Facets are additional data which you can attach to a query. This helps with returning aggregate statistics alongside regular query results. The aggregate statistics are a core part of elasticsearch, and are exposed through the Search API.
An example would be to consider searching for your ex-colleagues who worked with you. The best example from the above screenshot is when you want to find colleagues whose “Past Company” was “ABC Company”.
Facets are highly configurable. In addition to counting distinct field values, facets can count by more complex groupings, such as spans of time, nest filters, and even include full, nested, elasticsearch queries.
Here is an example of a Geo Distance Facet which is included as part of an ElasticSearch Query.&lt;/p&gt;

&lt;p&gt;Image courtesy of Karmi.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Machine Data and Big Data</title>
   <link href="/machine-data-and-big-data"/>
   <updated>2013-08-29T00:00:00-05:00</updated>
   <id>/machine-data-and-big-data</id>
   <content type="html">&lt;p&gt;Business applications, Sensors in Factories and Large equipment and their supporting systems are a rich source of data. Every technical component in a functioning system produces logging information.  Business application logs are detailed logs and can contain every transaction the customer or user has executed on that application. It doesn’t matter if the transaction was successful or whether it failed - there are insights you can get from Your Log files.
System or maching logs have variety, a large number of data sources and formats which are unique based on the application / system which is generating that.
Its fast moving, a typical enterprise creates log files for every second
volume of data, data is recorded for events and for time periods.
A business transaction will fan out and create 100’s of log and audit table entries. 
To get a big picture of your operations environment, this rich and complex technical information needs to be analyzed. You need to be able to get data which is relevant to you and this in turn presents a challenge for the software performance engineer or the Operations team. The Operations team is managing a larger and large number of real and virtual environments and the business is asking for more frequent functionality packed releases into the product.
Some typical log files which an enterprise deals with are :
• Network packet flow information from routers and switches• Storage subsystem metrics• Database metrics• Application servers from Log4j messages• Microsoft WMI• Web Server information from Apache• Operating system information from AIX, Linux, and VMWare• End User experience.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>What is Hive ?</title>
   <link href="/what-is-hive"/>
   <updated>2013-08-28T00:00:00-05:00</updated>
   <id>/what-is-hive</id>
   <content type="html">&lt;p&gt;It is a Data Warehouse system layer built on Hadoop.
Allows you to define a structure for your unstructured Big data.
Simplifies queries using a SQL syntax call HQL.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>SQL for Big Data - Key Initiatives</title>
   <link href="/sql-for-big-data-key-initiatives"/>
   <updated>2013-08-28T00:00:00-05:00</updated>
   <id>/sql-for-big-data-key-initiatives</id>
   <content type="html">&lt;p&gt;These are some SQL-for-Big Data initiatives which are getting some press:
Facebook’s Presto, a real-time query engine that provides a direct SQL interface to Facebook’s Hadoop data warehouse. Facebook plans on releasing Presto as an open-source project this fall.
Amazon Web Services’ RedShift. The service provides an SQL-based data warehouse service that can handle queries against databases of up to 1.6 petabytes.
HortonWorks’ Stinger initiative, an effort to improve the SQL interface of Hive and make Hive 100 times faster.
IBM’s BigSQL, an SQL query engine for Hadoop. BigSQL bypasses MapReduce and runs against the Hadoop Distributed File System for read-only queries and HBase (the Hadoop database engine) for transactional queries that perform reads and writes of data.
EMC’s HAWQ, an SQL query engine for the company’s Pivotal HD version of Hadoop.
Cloudera’s Impala, a real-time ad-hoc query interface to Hadoop introduced last October.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Key Hadoop Components </title>
   <link href="/key-hadoop-components"/>
   <updated>2013-08-28T00:00:00-05:00</updated>
   <id>/key-hadoop-components</id>
   <content type="html">&lt;p&gt;The three major categories of components in a Hadoop deployment are Client machines, Masters nodes, and Slave nodes.  
The Master nodes oversees the two key functional pieces that make up Hadoop: storing lots of data (HDFS), and running parallel computations on all that data (Map Reduce).  
The Name Node oversees and coordinates the data storage function (HDFS), while the Job Tracker oversees and coordinates the parallel processing of data using Map Reduce.  
Slave Nodes make up the vast majority of machines and do all the dirty work of storing the data and running the computations.  Each slave runs both a Data Node and Task Tracker daemon that communicate with and receive instructions from their master nodes.  
The Task Tracker daemon is a slave to the Job Tracker, the Data Node daemon a slave to the Name Node.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Scale 'out and not 'up'</title>
   <link href="/scale-out-and-not-up"/>
   <updated>2013-08-27T00:00:00-05:00</updated>
   <id>/scale-out-and-not-up</id>
   <content type="html">&lt;p&gt;Scale “out”, not “up”. For data-intensive workloads, a large number of commodity low-end servers (i.e., the scaling “out” approach) is preferred over a small number of high-end servers (i.e., the scaling “up” approach). 
The latter approach of purchasing symmetric multi-processing (SMP) machines with a large number of processor sockets (dozens, even hundreds) and a large amount of shared memory (hundreds or even thousands of gigabytes) is not effective cost wise, since the costs of such machines do not scale linearly (i.e., a machine with twice as many processors is often significantly more than twice as expensive). On the other hand, the low-end server market overlaps with the high-volume desktop computing market, which has the effect of keeping prices low due to competition, interchangeable components, and economies of scale.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>What is a Theta Join ?</title>
   <link href="/what-is-a-theta-join"/>
   <updated>2013-08-26T00:00:00-05:00</updated>
   <id>/what-is-a-theta-join</id>
   <content type="html">&lt;p&gt;The most general join operation is Theta Join (or q join). The Theta Join is defined as the result of performing a selection operation using comparison operator Theta (q), on the product. In other words, a join operation with a general join condition using Theta (q) operator is called a Theta Join.
For example, if you want only those tuples of the product of two relations ‘Student1’ and ‘Student2’ whose value is ‘L’ in the attribute ‘City’, Theta joinoperation is written as:&lt;/p&gt;

&lt;p&gt; 
Student1 TIMES student2 WHERE City =’L’This is equivalent to: 
Student1 TIMES student2 GIVING temp
 SELECT temp WHERE City =’L’&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>What is a Join Operation ?</title>
   <link href="/what-is-a-join-operation"/>
   <updated>2013-08-26T00:00:00-05:00</updated>
   <id>/what-is-a-join-operation</id>
   <content type="html">&lt;p&gt;The join operation is used to combine related tuples from two relations. This operation is very important in relational databases because it allows to process relationship among relations.
The join operation is the combination of the product, selection and projection operations. The join operation on two relations is performed as follows:
Product operation is performed on two relations.
Selection (SELECT) operation is performed to eliminate duplicate tuples by the join criteria or condition.
Projection (PROJECT) operation is performed to remove some attributes.
The PROJECT operation is another unary operation. This operation returns a set of tuples containing a subset of the attributes in the original relation. Thus, as we state that the SELECT operation selects some rows and discards the others. The PROJECT operation, on the other hand, selects some columns of the relation and discards the other column. The PROJECT operation can be viewed as the vertical filter of the relation.
Here is a wikipedia article on the Join Operation .&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Left Outer Join Example</title>
   <link href="/left-outer-join-example"/>
   <updated>2013-08-26T00:00:00-05:00</updated>
   <id>/left-outer-join-example</id>
   <content type="html">&lt;p&gt;So I have a products table :&lt;/p&gt;

&lt;p&gt;And I have a Sales table:&lt;/p&gt;

&lt;p&gt;If I want to find the sales for ALL products including the ones which are not present in the sales table, I can do this ( SQLITE syntax) :
select p.productname, 
case when sum(amount) is null then 0 else sum(s.amount) end as totalsales 
from product p left outer join sale s on p.productcode = s.productcode 
where s.productcode is null or s.productcode is not null group by p.productname &lt;/p&gt;

&lt;p&gt;One of the best examples I have seen for Outer and Inner joins is at CodingHorror&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title></title>
   <link href="/excel-analysis-using-play-d3-js-and-mongodb-a"/>
   <updated>2013-07-17T00:00:00-05:00</updated>
   <id>/excel-analysis-using-play-d3-js-and-mongodb-a</id>
   <content type="html">&lt;p&gt;Excel analysis using Play, D3.js and MongoDB - A quick overview of filtering  multi-variate datasets. Multivariate or high-dimensional (HiD) systems are hard to visualize because we are wired for a 3D world. Many different systems have been suggested to help visualize HiD data. Most of them use some system of subspace selection to reduce the dimensionality to 2 or 3 (e.g. 1-4) or use some procedure to identify important axes (e.g. principal component analysis or projection pursuit).
When doing multivariate analysis, the big picture is usually where you want to start, for meaningful observations, believe it or not, can be gleaned from the clutter. A display with this much data cannot be used to explore the details, but it can be used to search for predominant patterns and exceptions. &lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Arms Visualization from Google</title>
   <link href="/arms-visualization-from-google"/>
   <updated>2013-04-01T00:00:00-05:00</updated>
   <id>/arms-visualization-from-google</id>
   <content type="html">&lt;p&gt;Arms Visualization from Google&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>U.S State Visualization example - Long commute - Another D3 example</title>
   <link href="/u-s-state-visualization-example-long-commute"/>
   <updated>2013-03-24T00:00:00-05:00</updated>
   <id>/u-s-state-visualization-example-long-commute</id>
   <content type="html">&lt;p&gt;Here is another example of using D3 to generate stats driven visualization. 
I wanted to read the data from Google spreadsheets but then the lazy me thought that it will be easier just to add the traffic ratio attribute within the “us-state-centroids.json” file.
Here is how it looks now :&lt;/p&gt;

&lt;p&gt;The large circles indicates large commutes.
As you see most of the data is not even complete and since this just a work in progress, I wil make another revision to it hopefully shortly.
The full html file to the U.S visualization can be found here.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Basics : What are the different Data Types</title>
   <link href="/basics-what-are-the-different-data-types"/>
   <updated>2013-03-18T00:00:00-05:00</updated>
   <id>/basics-what-are-the-different-data-types</id>
   <content type="html">&lt;p&gt;There are only two broad types of Data :
Qualititative  and  Quantitative.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Qualitative data types can be further sub categorized into the following&lt;/em&gt; :&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Nominal&lt;/strong&gt; : They are unordered collections of symbolic names without units. For instance, the names of the orbiters, such as Hubble, Magellan, Mariner, Viking and Voyager form a nominal data set. The name ‘Nominal’ comes from the Latin nomen, meaning ‘name’ and nominal data are items which are differentiated by a simple naming system.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Ordinal&lt;/strong&gt; : Items on an ordinal scale are set into some kind of order by their position on the scale. This may indicate such as temporal position, superiority, etc.
The order of items is often defined by assigning numbers to them to show their relative position. Letters or other sequential symbols may also be used as appropriate. For example, characters are ordinal because we can call ‘A’ the first character, ‘B’ the second, etc.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Quantitative data types&lt;/em&gt;
These are usually described as numbers and can be sub-categorized as: &lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Discrete data&lt;/strong&gt;: Can take certain values ( like whole numbers). They have finite values, or buckets. You can count them. e.g. The number of questions taken in a survey would be discrete—there are a finite and countable number of questions.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Continuous data&lt;/strong&gt;: Continuous data technically have an infinite number of steps, which form a continuum. e.g. Time to complete a task is continuous since it could take 178.8977687 seconds. &lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Matrix responses - Process of design</title>
   <link href="/matrix-responses-process-of-design"/>
   <updated>2013-03-17T00:00:00-05:00</updated>
   <id>/matrix-responses-process-of-design</id>
   <content type="html">&lt;p&gt;This post is help the readers get an idea of how we approach some of the visualization problems.
For a matrix type question in a survey, like the one below, the visualization elements to understand the aggregated responses gets quite complicated.&lt;/p&gt;

&lt;p&gt; 
What are we trying to get here - What questions do we need answered to deal with responses from the matrix question above ?
For example, we are looking at the following :
1. How many people ‘Liked’  HBO for example ?
2. How can I compare - How many people ‘Liked’ HBO vs How many ‘Liked’  Star Movies ?
3. How can I compare - How many people ‘Liked’ HBO vs How many people ‘Disliked’ SONY PIX ?
I am not going through an exhaustive list of questions based on different answer types (between 1 - Dislike and 5 - Like) and the movie channels ( SONY PIX, AXN etct) because you can substitute that within the question above.
But I think we have covered the most important questions around matrix responses above.
Let’s see if we can answer them by asking more questions :)
What is our smallest dataset we can deal with when dealing with these questions ?
The smallest one would be  the following : [Option , Scale , Response Count], for e.g. [“HBO”, Dislike, 5]. If we have had this dataset, then we could answer question 1 above.
What is the best way to present that dataset ?
Maybe we can use 3 axis’s, because there are three datapoints; 3D ?&lt;/p&gt;

&lt;p&gt; 
The blue dot above is the datapoint we are trying to visualize.  Doesn’t this look a teeny bit intimidating and we have only our smallest meaningful dataset for a survey response.
3D is cool. But in the diagram above, without the lines connecting the blue dot to the axis’s this would be hard to understand.
What if we removed an axis?  Since the Response count is very chartable because its a number, we are left with the other two axises. But the Dislike to Like is a scale, which means there is already a number assigned to it where 1 is Dislike and 5 is Like. So we are really left with the Option axis.
What if we color coded these options - lets use Blue for HBO.&lt;/p&gt;

&lt;p&gt;Doesn’t this look much more easier to read ? . What is missing here ? . A legend which says HBO = blue.
Now let’s add couple more responses to this -  [“HBO”, Like, 4], [“Star Movies”, Like, 5],[“SONY PIX”, Dislike, 4]
Before adding these responses, we need to come up with a color code, let’s say Star Movies is green and SONY PIX is Orange.  So this is what the visualization will look like :&lt;/p&gt;

&lt;p&gt;So the color coding for the chart above is  - HBO=Blue, Star Movies=Green, SONY PIX=Orange. 
Now, trying answering the questions we had at the beginning of the post, Easy to visualize and easy to answer right?&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>I.O.U - questions for visualization</title>
   <link href="/i-o-u-questions-for-visualization"/>
   <updated>2013-03-17T00:00:00-05:00</updated>
   <id>/i-o-u-questions-for-visualization</id>
   <content type="html">&lt;p&gt;I am a firm believer that the questions you ask will drive the right kind of visualization ( I just found out that the word is mainly spelt visualisation i.e with an s instead of z in almost all of Europe). 
Other than the fact that the data has to be Relevant (duh?) to the question asked, here are three simple questions I ask to help with coming up with options for visualization.  I summarize it as the I.O.U principle.
(I)nteresting
What is really interesting about the data for the audience?.
Is there a way to show this interesting piece of information? .
Can I make this data more interesting?.
Is there a way I can design the visualization elements to make it more interesting?.  
Is the context for the data interesting?.
(O)utside
What context can I give from the outside that is relevant to the audience? 
What are the big trends or happenings outside the data which is currently not visualized?
What factors from the outside is influencing your decision and what have you introduced into this visualization ?
Are there relevant processes or people outside this which we need to consider to complete this visualization ?
(U) as in (U)ser
What are your important key measurements ?
Does the design make sense to you ?
How can we make this simpler for you to use and to understand ?
How do you like to present this ?
How do you like to share this ?&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Agile is good, but focus on Zero Overhead</title>
   <link href="/zero-overhead-principle"/>
   <updated>2013-03-01T00:00:00-06:00</updated>
   <id>/zero-overhead-principle</id>
   <content type="html">&lt;p&gt;Introducing new forms of visualization is an iterative process.  We work in an agile manner and release features at a minimum on a monthly basis.  Some of our visualization changes are pretty radical and will have user’s playing for some time to get ‘it’.  It is quite challenging to introduce new ways of visualizations and also to ensure that  users get ‘it’ without too much of a hassle.
DJ Patil’s and Josh Elman’s latest post on Techcrunch has kind of called this the ‘Zero Overhead’ Principle. &lt;/p&gt;

&lt;p&gt;“The real challenge for analysts is that they are already overloaded and tend to ignore additional tools that require training (remember these guys have real time pressure).  So we had to adopt a different mindset. Our products had to work naturally with the analysts’ work styles. Period.  That’s the Zero Overhead Principle. Put another way, our products had to teach the user as they went along. In essence, we were really just building enterprise products with a consumer mindset.”&lt;/p&gt;

&lt;p&gt;This also has a great video on how they used data driven science to improve user engagement at Twitter.
The key lessons from him are :&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Focus on building a “glide path.”&lt;/li&gt;
  &lt;li&gt;Use data to find friction&lt;/li&gt;
  &lt;li&gt;Prioritize the design experience&lt;/li&gt;
&lt;/ol&gt;
</content>
 </entry>
 
 <entry>
   <title>Fundamental Challenges in Mobile Data Visualization</title>
   <link href="/fundamental-challenges-in-mobile-data-visualization"/>
   <updated>2012-10-12T00:00:00-05:00</updated>
   <id>/fundamental-challenges-in-mobile-data-visualization</id>
   <content type="html">&lt;h2 id=&quot;location-location-location&quot;&gt;1. Location. Location. Location.&lt;/h2&gt;
&lt;p&gt;We are not talking about ordinary real estate here. Mobile realestate is scarce. Finding the right medium on minimal real estate and designing visual components to tell the story is essentially the hardest part of this endeavour.&lt;/p&gt;

&lt;h2 id=&quot;aligning-the-message&quot;&gt;2. Aligning the message&lt;/h2&gt;
&lt;p&gt;Data is fine. Essentially Data visualization is 70% Data and 30% Visualization.  So you would think that if we have the data you would have probably solved 70% of the problem.  In some cases its true and I would agree. I have worked for medium to large enterprises and I see that the larger the enterprise gets, proportionally it gets more challenging to get quality data.  But what is most important is the messaging which goes along with the visualization needs to be aligned.&lt;/p&gt;

&lt;p&gt;The picture above is a little fuzzy (but thanks to Stephen Few), the concept is clear - the message on the top is not really aligned with the graph below.  Now this could be because some additional information was missed or there was not enough space to explain this in a presentation (kind of goes back to point #1). But you would ask how is this problem really related to Mobile Data Visualization ?  The answer is - drawing on mobile devices ( iPads, iPhones, Androids and Blackberry OS’s) is challenging from a technical standpoint and what almost all vendors do is to start with the basic chart types which might not help in getting the message across.&lt;/p&gt;

&lt;h2 id=&quot;just-enough-data&quot;&gt;3. Just enough data&lt;/h2&gt;
&lt;p&gt;Going mobile presents a challenge for visualaization in terms of securing data at all stages of the analytic process, primarily for data transmission and device access. For this reason many vendors are opting for a mobile product that provides functionality via server-side architecture with the use of a Web infrastructure like HTML5. Information then can be stored, managed, and provided using a mobile BI server, where the risk of exposing sensitive data is lower than storing it on a mobile device that could be stolen. 
The other aspect of this is performance of the visualization tool itself.  If there are datapoints which are not relevant to the visualization medium then there is no point sending that data to the device itself. &lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Jekyll Introduction</title>
   <link href="/jekyll-introduction"/>
   <updated>2011-12-29T00:00:00-06:00</updated>
   <id>/jekyll-introduction</id>
   <content type="html">
&lt;p&gt;This Jekyll introduction will outline specifically  what Jekyll is and why you would want to use it.
Directly following the intro we&amp;#8217;ll learn exactly &lt;em&gt;how&lt;/em&gt; Jekyll does what it does.&lt;/p&gt;

&lt;h2 id=&quot;overview&quot;&gt;Overview&lt;/h2&gt;

&lt;h3 id=&quot;what-is-jekyll&quot;&gt;What is Jekyll?&lt;/h3&gt;

&lt;p&gt;Jekyll is a parsing engine bundled as a ruby gem used to build static websites from
dynamic components such as templates, partials, liquid code, markdown, etc. Jekyll is known as &amp;#8220;a simple, blog aware, static site generator&amp;#8221;.&lt;/p&gt;

&lt;h3 id=&quot;examples&quot;&gt;Examples&lt;/h3&gt;

&lt;p&gt;This website is created with Jekyll. &lt;a href=&quot;https://github.com/mojombo/jekyll/wiki/Sites&quot;&gt;Other Jekyll websites&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;what-does-jekyll-do&quot;&gt;What does Jekyll Do?&lt;/h3&gt;

&lt;p&gt;Jekyll is a ruby gem you install on your local system.
Once there you can call &lt;code&gt;jekyll --server&lt;/code&gt; on a directory and provided that directory
is setup in a way jekyll expects, it will do magic stuff like parse markdown/textile files,
compute categories, tags, permalinks, and construct your pages from layout templates and partials.&lt;/p&gt;

&lt;p&gt;Once parsed, Jekyll stores the result in a self-contained static &lt;code&gt;_site&lt;/code&gt; folder.
The intention here is that you can serve all contents in this folder statically from a plain static web-server.&lt;/p&gt;

&lt;p&gt;You can think of Jekyll as a normalish dynamic blog but rather than parsing content, templates, and tags
on each request, Jekyll does this once &lt;em&gt;beforehand&lt;/em&gt; and caches the &lt;em&gt;entire website&lt;/em&gt; in a folder for serving statically.&lt;/p&gt;

&lt;h3 id=&quot;jekyll-is-not-blogging-software&quot;&gt;Jekyll is Not Blogging Software&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Jekyll is a parsing engine.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Jekyll does not come with any content nor does it have any templates or design elements.
This is a common source of confusion when getting started.
Jekyll does not come with anything you actually use or see on your website - you have to make it.&lt;/p&gt;

&lt;h3 id=&quot;why-should-i-care&quot;&gt;Why Should I Care?&lt;/h3&gt;

&lt;p&gt;Jekyll is very minimalistic and very efficient.
The most important thing to realize about Jekyll is that it creates a static representation of your website requiring only a static web-server.
Traditional dynamic blogs like Wordpress require a database and server-side code.
Heavily trafficked dynamic blogs must employ a caching layer that ultimately performs the same job Jekyll sets out to do; serve static content.&lt;/p&gt;

&lt;p&gt;Therefore if you like to keep things simple and you prefer the command-line over an admin panel UI then give Jekyll a try.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Developers like Jekyll because we can write content like we write code:&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Ability to write content in markdown or textile in your favorite text-editor.&lt;/li&gt;
  &lt;li&gt;Ability to write and preview your content via localhost.&lt;/li&gt;
  &lt;li&gt;No internet connection required.&lt;/li&gt;
  &lt;li&gt;Ability to publish via git.&lt;/li&gt;
  &lt;li&gt;Ability to host your blog on a static web-server.&lt;/li&gt;
  &lt;li&gt;Ability to host freely on GitHub Pages.&lt;/li&gt;
  &lt;li&gt;No database required.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;how-jekyll-works&quot;&gt;How Jekyll Works&lt;/h1&gt;

&lt;p&gt;The following is a complete but concise outline of exactly how Jekyll works.&lt;/p&gt;

&lt;p&gt;Be aware that core concepts are introduced in rapid succession without code examples.
This information is not intended to specifically teach you how to do anything, rather it
is intended to give you the &lt;em&gt;full picture&lt;/em&gt; relative to what is going on in Jekyll-world.&lt;/p&gt;

&lt;p&gt;Learning these core concepts should help you avoid common frustrations and ultimately
help you better understand the code examples contained throughout Jekyll-Bootstrap.&lt;/p&gt;

&lt;h2 id=&quot;initial-setup&quot;&gt;Initial Setup&lt;/h2&gt;

&lt;p&gt;After &lt;a href=&quot;/index.html#start-now&quot;&gt;installing jekyll&lt;/a&gt; you&amp;#8217;ll need to format your website directory in a way jekyll expects.
Jekyll-bootstrap conveniently provides the base directory format.&lt;/p&gt;

&lt;h3 id=&quot;the-jekyll-application-base-format&quot;&gt;The Jekyll Application Base Format&lt;/h3&gt;

&lt;p&gt;Jekyll expects your website directory to be laid out like so:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;.
|-- _config.yml
|-- _includes
|-- _layouts
|   |-- default.html
|   |-- post.html
|-- _posts
|   |-- 2011-10-25-open-source-is-good.markdown
|   |-- 2011-04-26-hello-world.markdown
|-- _site
|-- index.html
|-- assets
    |-- css
        |-- style.css
    |-- javascripts
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;_config.yml&lt;/strong&gt;
  Stores configuration data.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;_includes&lt;/strong&gt;
  This folder is for partial views.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;_layouts&lt;/strong&gt;
  This folder is for the main templates your content will be inserted into.
  You can have different layouts for different pages or page sections.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;_posts&lt;/strong&gt;
  This folder contains your dynamic content/posts.
  the naming format is required to be &lt;code&gt;@YEAR-MONTH-DATE-title.MARKUP@&lt;/code&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;_site&lt;/strong&gt;
  This is where the generated site will be placed once Jekyll is done transforming it.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;assets&lt;/strong&gt;
  This folder is not part of the standard jekyll structure.
  The assets folder represents &lt;em&gt;any generic&lt;/em&gt; folder you happen to create in your root directory.
  Directories and files not properly formatted for jekyll will be left untouched for you to serve normally.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;(read more: &lt;a href=&quot;https://github.com/mojombo/jekyll/wiki/Usage&quot;&gt;https://github.com/mojombo/jekyll/wiki/Usage&lt;/a&gt;)&lt;/p&gt;

&lt;h3 id=&quot;jekyll-configuration&quot;&gt;Jekyll Configuration&lt;/h3&gt;

&lt;p&gt;Jekyll supports various configuration options that are fully outlined here:
(&lt;a href=&quot;https://github.com/mojombo/jekyll/wiki/Configuration&quot;&gt;https://github.com/mojombo/jekyll/wiki/Configuration&lt;/a&gt;)&lt;/p&gt;

&lt;h2 id=&quot;content-in-jekyll&quot;&gt;Content in Jekyll&lt;/h2&gt;

&lt;p&gt;Content in Jekyll is either a post or a page.
These content &amp;#8220;objects&amp;#8221; get inserted into one or more templates to build the final output for its respective static-page.&lt;/p&gt;

&lt;h3 id=&quot;posts-and-pages&quot;&gt;Posts and Pages&lt;/h3&gt;

&lt;p&gt;Both posts and pages should be written in markdown, textile, or HTML and may also contain Liquid templating syntax.
Both posts and pages can have meta-data assigned on a per-page basis such as title, url path, as well as arbitrary custom meta-data.&lt;/p&gt;

&lt;h3 id=&quot;working-with-posts&quot;&gt;Working With Posts&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Creating a Post&lt;/strong&gt;
Posts are created by properly formatting a file and placing it the &lt;code&gt;_posts&lt;/code&gt; folder.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Formatting&lt;/strong&gt;
A post must have a valid filename in the form &lt;code&gt;YEAR-MONTH-DATE-title.MARKUP&lt;/code&gt; and be placed in the &lt;code&gt;_posts&lt;/code&gt; directory.
If the data format is invalid Jekyll will not recognize the file as a post. The date and title are automatically parsed from the filename of the post file.
Additionally, each file must have &lt;a href=&quot;https://github.com/mojombo/jekyll/wiki/YAML-Front-Matter&quot;&gt;YAML Front-Matter&lt;/a&gt; prepended to its content.
YAML Front-Matter is a valid YAML syntax specifying meta-data for the given file.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Order&lt;/strong&gt;
Ordering is an important part of Jekyll but it is hard to specify a custom ordering strategy.
Only reverse chronological and chronological ordering is supported in Jekyll.&lt;/p&gt;

&lt;p&gt;Since the date is hard-coded into the filename format, to change the order, you must change the dates in the filenames.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Tags&lt;/strong&gt;
Posts can have tags associated with them as part of their meta-data.
Tags may be placed on posts by providing them in the post&amp;#8217;s YAML front matter.
You have access to the post-specific tags in the templates. These tags also get added to the sitewide collection.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Categories&lt;/strong&gt;
Posts may be categorized by providing one or more categories in the YAML front matter.
Categories offer more significance over tags in that they can be reflected in the URL path to the given post.
Note categories in Jekyll work in a specific way.
If you define more than one category you are defining a category hierarchy &amp;#8220;set&amp;#8221;.
Example:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;---
title :  Hello World
categories : [lessons, beginner]
---
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This defines the category hierarchy &amp;#8220;lessons/beginner&amp;#8221;. Note this is &lt;em&gt;one category&lt;/em&gt; node in Jekyll.
You won&amp;#8217;t find &amp;#8220;lessons&amp;#8221; and &amp;#8220;beginner&amp;#8221; as two separate categories unless you define them elsewhere as singular categories.&lt;/p&gt;

&lt;h3 id=&quot;working-with-pages&quot;&gt;Working With Pages&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Creating a Page&lt;/strong&gt;
Pages are created by properly formatting a file and placing it anywhere in the root directory or subdirectories that do &lt;em&gt;not&lt;/em&gt; start with an underscore.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Formatting&lt;/strong&gt;
In order to register as a Jekyll page the file must contain &lt;a href=&quot;https://github.com/mojombo/jekyll/wiki/YAML-Front-Matter&quot;&gt;YAML Front-Matter&lt;/a&gt;.
Registering a page means 1) that Jekyll will process the page and 2) that the page object will be available in the &lt;code&gt;site.pages&lt;/code&gt; array for inclusion into your templates.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Categories and Tags&lt;/strong&gt;
Pages do not compute categories nor tags so defining them will have no effect.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Sub-Directories&lt;/strong&gt;
If pages are defined in sub-directories, the path to the page will be reflected in the url.
Example:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;.
|-- people
    |-- bob
        |-- essay.html
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This page will be available at &lt;code&gt;http://yourdomain.com/people/bob/essay.html&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Recommended Pages&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;index.html&lt;/strong&gt;
You will always want to define the root index.html page as this will display on your root URL.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;404.html&lt;/strong&gt;
Create a root 404.html page and GitHub Pages will serve it as your 404 response.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;sitemap.html&lt;/strong&gt;
Generating a sitemap is good practice for SEO.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;about.html&lt;/strong&gt;
A nice about page is easy to do and gives the human perspective to your website.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;templates-in-jekyll&quot;&gt;Templates in Jekyll&lt;/h2&gt;

&lt;p&gt;Templates are used to contain a page&amp;#8217;s or post&amp;#8217;s content.
All templates have access to a global site object variable: &lt;code&gt;site&lt;/code&gt; as well as a page object variable: &lt;code&gt;page&lt;/code&gt;.
The site variable holds all accessible content and metadata relative to the site.
The page variable holds accessible data for the given page or post being rendered at that point.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Create a Template&lt;/strong&gt;
Templates are created by properly formatting a file and placing it in the &lt;code&gt;_layouts&lt;/code&gt; directory.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Formatting&lt;/strong&gt;
Templates should be coded in HTML and contain YAML Front Matter.
All templates can contain Liquid code to work with your site&amp;#8217;s data.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Rending Page/Post Content in a Template&lt;/strong&gt;
There is a special variable in all templates named : &lt;code&gt;content&lt;/code&gt;.
The &lt;code&gt;content&lt;/code&gt; variable holds the page/post content including any sub-template content previously defined.
Render the content variable wherever you want your main content to be injected into your template:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;...
&amp;lt;body&amp;gt;
  &amp;lt;div id=&quot;sidebar&quot;&amp;gt; ... &amp;lt;/div&amp;gt;
  &amp;lt;div id=&quot;main&quot;&amp;gt;
    &amp;#123;{content}&amp;#125;
  &amp;lt;/div&amp;gt;
&amp;lt;/body&amp;gt;
...&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;sub-templates&quot;&gt;Sub-Templates&lt;/h3&gt;

&lt;p&gt;Sub-templates are exactly templates with the only difference being they
define another &amp;#8220;root&amp;#8221; layout/template within their YAML Front Matter.
This essentially means a template will render inside of another template.&lt;/p&gt;

&lt;h3 id=&quot;includes&quot;&gt;Includes&lt;/h3&gt;
&lt;p&gt;In Jekyll you can define include files by placing them in the &lt;code&gt;_includes&lt;/code&gt; folder.
Includes are NOT templates, rather they are just code snippets that get included into templates.
In this way, you can treat the code inside includes as if it was native to the parent template.&lt;/p&gt;

&lt;p&gt;Any valid template code may be used in includes.&lt;/p&gt;

&lt;h2 id=&quot;using-liquid-for-templating&quot;&gt;Using Liquid for Templating&lt;/h2&gt;

&lt;p&gt;Templating is perhaps the most confusing and frustrating part of Jekyll.
This is mainly due to the fact that Jekyll templates must use the Liquid Templating Language.&lt;/p&gt;

&lt;h3 id=&quot;what-is-liquid&quot;&gt;What is Liquid?&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/Shopify/liquid&quot;&gt;Liquid&lt;/a&gt; is a secure templating language developed by &lt;a href=&quot;http://shopify.com&quot;&gt;Shopify&lt;/a&gt;.
Liquid is designed for end-users to be able to execute logic within template files
without imposing any security risk on the hosting server.&lt;/p&gt;

&lt;p&gt;Jekyll uses Liquid to generate the post content within the final page layout structure and as the primary interface for working with
your site and post/page data.&lt;/p&gt;

&lt;h3 id=&quot;why-do-we-have-to-use-liquid&quot;&gt;Why Do We Have to Use Liquid?&lt;/h3&gt;

&lt;p&gt;GitHub uses Jekyll to power &lt;a href=&quot;http://pages.github.com/&quot;&gt;GitHub Pages&lt;/a&gt;.
GitHub cannot afford to run arbitrary code on their servers so they lock developers down via Liquid.&lt;/p&gt;

&lt;h3 id=&quot;liquid-is-not-programmer-friendly&quot;&gt;Liquid is Not Programmer-Friendly.&lt;/h3&gt;

&lt;p&gt;The short story is liquid is not real code and its not intended to execute real code.
The point being you can&amp;#8217;t do jackshit in liquid that hasn&amp;#8217;t been allowed explicitly by the implementation.
What&amp;#8217;s more you can only access data-structures that have been explicitly passed to the template.&lt;/p&gt;

&lt;p&gt;In Jekyll&amp;#8217;s case it is not possible to alter what is passed to Liquid without hacking the gem or running custom plugins.
Both of which cannot be supported by GitHub Pages.&lt;/p&gt;

&lt;p&gt;As a programmer - this is very frustrating.&lt;/p&gt;

&lt;p&gt;But rather than look a gift horse in the mouth we are going to
suck it up and view it as an opportunity to work around limitations and adopt client-side solutions when possible.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Aside&lt;/strong&gt;
My personal stance is to not invest time trying to hack liquid. It&amp;#8217;s really unnecessary
&lt;em&gt;from a programmer&amp;#8217;s&lt;/em&gt; perspective. That is to say if you have the ability to run custom plugins (i.e. run arbitrary ruby code)
you are better off sticking with ruby. Toward that end I&amp;#8217;ve built &lt;a href=&quot;http://github.com/plusjade/mustache-with-jekyll&quot;&gt;Mustache-with-Jekyll&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;static-assets&quot;&gt;Static Assets&lt;/h2&gt;

&lt;p&gt;Static assets are any file in the root or non-underscored subfolders that are not pages.
That is they have no valid YAML Front Matter and are thus not treated as Jekyll Pages.&lt;/p&gt;

&lt;p&gt;Static assets should be used for images, css, and javascript files.&lt;/p&gt;

&lt;h2 id=&quot;how-jekyll-parses-files&quot;&gt;How Jekyll Parses Files&lt;/h2&gt;

&lt;p&gt;Remember Jekyll is a processing engine. There are two main types of parsing in Jekyll.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Content parsing.&lt;/strong&gt;
  This is done with textile or markdown.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Template parsing.&lt;/strong&gt;
This is done with the liquid templating language.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;And thus there are two main types of file formats needed for this parsing.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Post and Page files.&lt;/strong&gt;
All content in Jekyll is either a post or a page so valid posts and pages are parsed with markdown or textile.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Template files.&lt;/strong&gt;
  These files go in &lt;code&gt;_layouts&lt;/code&gt; folder and contain your blogs &lt;strong&gt;templates&lt;/strong&gt;. They should be made in HTML with the help of Liquid syntax.
  Since include files are simply injected into templates they are essentially parsed as if they were native to the template.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Arbitrary files and folders.&lt;/strong&gt;
Files that &lt;em&gt;are not&lt;/em&gt; valid pages are treated as static content and pass through
Jekyll untouched and reside on your blog in the exact structure and format they originally existed in.&lt;/p&gt;

&lt;h3 id=&quot;formatting-files-for-parsing&quot;&gt;Formatting Files for Parsing.&lt;/h3&gt;

&lt;p&gt;We&amp;#8217;ve outlined the need for valid formatting using &lt;strong&gt;YAML Front Matter&lt;/strong&gt;.
Templates, posts, and pages all need to provide valid YAML Front Matter even if the Matter is empty.
This is the only way Jekyll knows you want the file processed.&lt;/p&gt;

&lt;p&gt;YAML Front Matter must be prepended to the top of template/post/page files:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;---
layout: post
category : pages
tags : [how-to, jekyll]
---

... contents ...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Three hyphens on a new line start the Front-Matter block and three hyphens on a new line end the block.
The data inside the block must be valid YAML.&lt;/p&gt;

&lt;p&gt;Configuration parameters for YAML Front-Matter is outlined here:
&lt;a href=&quot;https://github.com/mojombo/jekyll/wiki/YAML-Front-Matter&quot;&gt;A comprehensive explanation of YAML Front Matter&lt;/a&gt;&lt;/p&gt;

&lt;h4 id=&quot;defining-layouts-for-posts-and-templates-parsing&quot;&gt;Defining Layouts for Posts and Templates Parsing.&lt;/h4&gt;

&lt;p&gt;The &lt;code&gt;layout&lt;/code&gt; parameter in the YAML Front Matter defines the template file for which the given post or template should be injected into.
If a template file specifies its own layout, it is effectively being used as a &lt;code&gt;sub-template.&lt;/code&gt;
That is to say loading a post file into a template file that refers to another template file with work in the way you&amp;#8217;d expect; as a nested sub-template.&lt;/p&gt;

&lt;h2 id=&quot;how-jekyll-generates-the-final-static-files&quot;&gt;How Jekyll Generates the Final Static Files.&lt;/h2&gt;

&lt;p&gt;Ultimately, Jekyll&amp;#8217;s job is to generate a static representation of your website.
The following is an outline of how that&amp;#8217;s done:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Jekyll collects data.&lt;/strong&gt;
  Jekyll scans the posts directory and collects all posts files as post objects. It then scans the layout assets and collects those and finally scans other directories in search of pages.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Jekyll computes data.&lt;/strong&gt;
  Jekyll takes these objects, computes metadata (permalinks, tags, categories, titles, dates) from them and constructs one
  big &lt;code&gt;site&lt;/code&gt; object that holds all the posts, pages, layouts, and respective metadata.
  At this stage your site is one big computed ruby object.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Jekyll liquifies posts and templates.&lt;/strong&gt;
  Next jekyll loops through each post file and converts (through markdown or textile) and &lt;strong&gt;liquifies&lt;/strong&gt; the post inside of its respective layout(s).
  Once the post is parsed and liquified inside the the proper layout structure, the layout itself is &amp;#8220;liquified&amp;#8221;.
 &lt;strong&gt;Liquification&lt;/strong&gt; is defined as follows: Jekyll initiates a Liquid template, and passes a simpler hash representation of the ruby site object as well as a simpler
  hash representation of the ruby post object. These simplified data structures are what you have access to in the templates.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Jekyll generates output.&lt;/strong&gt;
 Finally the liquid templates are &amp;#8220;rendered&amp;#8221;, thereby processing any liquid syntax provided in the templates
 and saving the final, static representation of the file.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;Notes.&lt;/strong&gt;
Because Jekyll computes the entire site in one fell swoop, each template is given access to
a global &lt;code&gt;site&lt;/code&gt; hash that contains useful data. It is this data that you&amp;#8217;ll iterate through and format
using the Liquid tags and filters in order to render it onto a given page.&lt;/p&gt;

&lt;p&gt;Remember, in Jekyll you are an end-user. Your API has only two components:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;The manner in which you setup your directory.&lt;/li&gt;
  &lt;li&gt;The liquid syntax and variables passed into the liquid templates.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;All the data objects available to you in the templates via Liquid are outlined in the &lt;strong&gt;API Section&lt;/strong&gt; of Jekyll-Bootstrap.
You can also read the original documentation here: &lt;a href=&quot;https://github.com/mojombo/jekyll/wiki/Template-Data&quot;&gt;https://github.com/mojombo/jekyll/wiki/Template-Data&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;I hope this paints a clearer picture of what Jekyll is doing and why it works the way it does.
As noted, our main programming constraint is the fact that our API is limited to what is accessible via Liquid and Liquid only.&lt;/p&gt;

&lt;p&gt;Jekyll-bootstrap is intended to provide helper methods and strategies aimed at making it more intuitive and easier to work with Jekyll =)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Thank you&lt;/strong&gt; for reading this far.&lt;/p&gt;

&lt;h2 id=&quot;next-steps&quot;&gt;Next Steps&lt;/h2&gt;

&lt;p&gt;Please take a look at []()
or jump right into &lt;a href=&quot;&quot;&gt;Usage&lt;/a&gt; if you&amp;#8217;d like.&lt;/p&gt;
</content>
 </entry>
 
 
</feed>